---
title: 'Lab 2: implementing marginal regression'
author: "Solutions"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error = TRUE)
```

## Install and Load Packages

Run the following code in the Console to install a new package called `snpstats` that we'll be using today:

```
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("snpStats")
```

Now, load this package along with a few others that will be helpful for our analysis. (You may need to install some of these other packages as well, especially if you've updated your version of R/RStudio since you took STAT 155.)

```{r load-packages, message = F}
library(snpStats)
library(dplyr)
library(ggplot2)
library(broom)
```


## Load Data

To download the data that we'll be using today, go to [this GitHub page](https://github.com/MareesAT/GWA_tutorial/) and download the `1_QC_GWAS.zip` file. Once you've downloaded that file successfully, you'll need to unzip it. On most computers, double-clicking the zipped file will unzip it, but you can also do it from the command line if that doesn't work. (Kelsey can help with this --- just raise your hand if you get stuck here!) 

Once you've finished downloading the data, update the strings below to reflect the correct path to the data on your computer. Here's what it looks like for me (you'll need to update this):

```{r file-paths}
# path to directory where plink files are stored
data.dir <- '/Users/kgrinde/Documents/Teaching/StatGen/data/MareesEtAl_Tutorial/1_QC_GWAS/'

# paste together name of file and path to directory
fam <- paste0(data.dir, 'HapMap_3_r3_1.fam')
bim <- paste0(data.dir, 'HapMap_3_r3_1.bim')
bed <- paste0(data.dir, 'HapMap_3_r3_1.bed')
```

> Collectively, the `.fam`, `.bim`, and `.bed` files make up the data that we'll be investigating today.
> The format of these files is known as *PLINK format*. 
> It is a common format for efficiently storing large genetic datasets.
> The `.bed` file contains the genotypes, the `.fam` file contains information on the individuals, and the `.bim` file contains information on the SNPs. 
>
> `PLINK` is a popular tool for analyzing genetic data and conducting GWAS. 
> (Learn more [here](https://www.cog-genomics.org/plink/)).
> We're going to be conducting our GWAS "by hand" so that we can understand the methods better, but in practice you'll find that many people use `PLINK` or other software programs instead. 
> Learning to use `PLINK` could make for an interesting final project (especially if one of your learning goals is related to developing your computational skills)!

> The data that we're using today come from the International HapMap project (also known as "HapMap").
> Read more about HapMap [here](https://www.genome.gov/10001688/international-hapmap-project).
> The data were processed by a group of researchers in the Netherlands and France for a tutorial they wrote on how to conduct a genome-wide association study.
> If you're interested, you can read that tutorial [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6001694/) and find the corresponding code on [GitHub](https://github.com/MareesAT/GWA_tutorial).
> The authors decided to focus their tutorial on an "ethnically homogeneous dataset," so although HapMap actually sampled individuals from a variety of populations across the world (see [this list](https://www.sanger.ac.uk/resources/downloads/human/hapmap3.html)), the data that we're using today only includes individuals from Utah with Northern and Western European ancestry (the "CEU" population).


Now, we can use the `read.plink` function in the `snpstats` package to read this data into R. (It might take a minute.)

```{r read-data, cache = TRUE}
hapmap <- read.plink(bed, bim, fam)
```

> Whenever you have a time-consuming code chunk in your RMarkdown file (like this one), knitting your document can be a pain. 
> In these cases, it can be helpful to `cache = TRUE`: once you've knit the file once, all future knits will skip this chunk (provided none of the code in the chunk has changed) and instead just load in the results from the last run. 
> This can be a huge time-saver! 
>
> Read more about caching [here](https://bookdown.org/yihui/rmarkdown-cookbook/cache.html).



## Explore Data

The new `hapmap` data object is a list of three items:

```{r explore-data}
names(hapmap)
```

- `genotypes` contains the genotype data
- `fam` contains information on each individual
- `map` contains information on each SNP


### Explore genotype data

Get info about the genotype data: 

```{r explore-genotype-matrix}
hapmap$genotypes
```

How many individuals do we have in this dataset? How many SNPs?

> There are 165 individuals (n = 165) and 1,457,897 SNPs (p = 1457897).



### Explore sample information

Look at the info we have on each individual:

```{r explore-sample-info}
head(hapmap$fam)
```

> The `fam` file keeps track of information about each of the individuals in our study.
> In this case, we have the following:
>
> - information about family relationships (`pedigree`, `father`, `mother`)
> - binary sex (`1` = male, `2` = female, `0` = unknown)
> - a binary simulated phenotype (`affected`: `1` = control, `2` = case)


We'll ignore this information for now. 


### Explore SNP information

We can also look at the info we have on each SNP:

```{r explore-snp-info}
head(hapmap$map)
```

What do you think each of these columns are telling us? Discuss with your group.

> Here's what each column represents:
>
> - `chromosome`: the chromosome on which the SNP resides
> - `snp.name`: the name of the SNP (commonly referred to as the "rsID")
> - `cM`: the abbreviation cM stands for *centiMorgans*; this is a unit of distance that we use when talking about how far about SNPs are from one another along the genome; we refer to this type of distance as "genetic distance"
> - `position`: this tell us the base pair position of the SNP (e.g., position = 1 would be the very first nucleotide in our DNA sequence); we refer to this as "physical (base pair) distance"
> - `allele.1`: this is one of the alleles at this SNP (according to the `PLINK` documentation, this is *usually* the minor allele)
> - `allele.2`: this is the other allele at this SNP (according to the `PLINK` documentation, this is *usually* the major allele)


One useful piece of information about these SNPs that the `map` data frame does not already contain is the minor allele frequency (MAF) --- that is, the frequency of the minor allele in this dataset. Thankfully, the `snpstats` package provides some helpful code for quickly calculating the MAF for each SNP in the dataset:

```{r calculate-MAF, cache = TRUE}
maf <- col.summary(hapmap$genotypes)$MAF
head(maf)
```

Notice that some of these SNPs have a MAF of zero! This means that everyone in the dataset has the same genotype at these positions. We refer to these SNPs as *monomorphic* (mono meaning "one").

Let's add the minor allele frequencies to our `map` data frame. (This will come in handy later.)

```{r add-MAF-to-SNP-info}
# add new MAF variable 
hapmap$map <- hapmap$map %>%
  mutate(MAF = maf)

# look at SNP info again
head(hapmap$map)
```



## Reformat data for analysis

The `snpstats` package uses a unique format to store data. Currently, genotypes are coded as 01, 02, and 03 (with 00 representing missing values:

```{r look-at-genotypes}
# look at first five rows/columns
hapmap$genotypes@.Data[1:5,1:5]
```


Let's convert this to the 0, 1, 2 (and NA) format that we've talked about in class:

```{r reformat-genotypes}
# convert from "SnpMatrix" to "numeric"
X <- as(hapmap$genotypes, "numeric")

# look at first five rows/columns to confirm conversion looks ok
X[1:5, 1:5]
```

If the conversion was successful, you should now see a matrix of 0's, 1's, and 2's. 


**Before you go on, check in with the others at your table. Was everyone able to get to this point successfully? Does anyone have any questions so far?**




## Simulate Trait

Let's simulate a trait that depends on the SNP known as *rs2476601*. Here's what we know about this SNP:

```{r look-at-causal-SNP}
hapmap$map %>%
  filter(snp.name == 'rs2476601')
```

We can learn more about this SNP by searching the `dbSNP` database: https://www.ncbi.nlm.nih.gov/snp/. Enter the rsID (the SNP's name) into the dbSNP search bar and see what you can learn. Summarize your findings here: 

> There is a lot of information about this SNP on dbSNP. A few things that stood out to me: 
>
> - This SNP is located on chromosome 1.
> - It is affiliated with (located in/near) two genes: *PTPN22* and *AP4B1-AS1*
> - Although there is some variation in allele frequencies across populations, in all of them the G allele is much more common (frequency > 90%) than the A allele. This matches what we see in our data.
> - It has been implicated as a potential risk factor for diabetes, rheumatoid arthritis, and other (mostly autoimmune) diseases.
> - It was mentioned in the Wellcome Trust GWAS paper that we read for Journal Club :)


Now, let's create a quantitative trait `y` that depends on the genotype at this SNP plus some random noise: 

```{r simulate-trait}
n <- nrow(X)
y <- X[,'rs2476601'] + rnorm(n, 0, 1)
head(y)
```

Since this is a simulation, we know by design that our trait `y` depends on SNP rs2476601 and nothing else. We can use this information to check how well our methods are working. We'll refer to rs2476601 as the *causal SNP* from here on out. 




## Run GWAS

In a real genetic study, we wouldn't know the location of the true causal SNP(s) beforehand, so we'd need to run a genome-wide association study to see if we can figure out which variants are associated with the trait. As we've discussed in class, the method we'll use for GWAS is *marginal regression*. 

### Getting started

To start, let's look at what happens when we run marginal regression on the first five SNPs in this dataset:

```{r fit-initial-models}
## fit models at first few SNPs
mod1 <- lm(y ~ X[,1])
mod2 <- lm(y ~ X[,2])
mod3 <- lm(y ~ X[,3])
mod4 <- lm(y ~ X[,4])
mod5 <- lm(y ~ X[,5])
```

```{r summarize-initial-models}
## look at the model summaries
tidy(mod1)
tidy(mod2)
tidy(mod3)
tidy(mod4)
tidy(mod5)
```

Do you notice anything weird about the 1st and 3rd SNPs? What do you think is going on here?

> Yes, we get NAs for the estimate, standard error, test statistics, and p-value for the slope of these two models. 
> It turns out that both of these SNPs are monomorphic: everyone in the dataset has the same genotype.
> Without variation in the genotypes that people carry at these positions, we can't estimate the association between these SNPs and the trait. 
> (Again, we have a situation of linear dependence: the column of minor allele counts is a linear combination of the intercept column. Since our design matrix isn't full rank, our least squares estimator is not defined.)

**Stop and discuss this question with your table before you move on.**



### Remove monomorphic SNPs

We're not going to get any useful information from any of these monomorphic SNPs, so let's remove them. We can remove these SNPs from the `map` data frame with a `filter` statement: fill in the blanks (___) below and then run this code chunk.

```{r remove-mono-from-map}
# keep only those SNPs with MAF > 0
map.clean <- hapmap$map %>%
  filter(maf > 0)
```

How many SNPs are left after filtering? How many did we remove?

> We have `r nrow(map.clean)` SNPs left after filtering. This means that we removed `r nrow(hapmap$map) - nrow(map.clean)` monomorphic SNPs.



Now, let's remove these monomorphic SNPs from our genotype matrix (`X`). Since we're working with a matrix here instead of a data frame, we can't use the `filter` function. Here's one way to remove the columns corresponding to the monomorphic SNPs from `X`:

```{r remove-mono-from-genotypes}
# create vector of which SNPs have a MAF of 0
monomorphic <- which(maf == 0) 
head(monomorphic) 

# remove columns in the monomorphic vector
X.clean <- X[,-monomorphic]
```

**Confirm that the new "clean" genotype matrix has the correct number of rows and columns before you move on.** 

> You should have `r nrow(X.clean)` rows and `r ncol(X.clean)` columns in this new genotype matrix. We didn't remove any people, but we did remove some SNPs.


### Analyze chromosome 1

Even after removing the monomorphic SNPs, we still have `r ncol(X.clean)` variants remaining. This might take awhile to analyze in R, so let's focus on just the SNPs on the first chromosome to start. 

Run the code chunk below to make a list of which SNPs live on chromosome 1:

```{r find-chr1-snps}
chr1.snps <- which(map.clean$chromosome == 1)
head(chr1.snps)
length(chr1.snps)
```


Now, we're going to loop through each of the SNPs on chromosome 1, fitting a linear regression model at each SNP. For each model, we'll record the estimates (`betas`), standard errors (`ses`), test statistics (`tstats`) and p-values (`pvals`) for the coefficient of interest (the slope).

```{r run-gwas-chr1, cache = TRUE}
# set up empty vectors for storing results
betas <- c()
ses <- c()
tstats <- c()
pvals <- c()

# loop through chromosome 1 SNPs
for(i in chr1.snps){
  # print out occasional updates telling us what SNP we're analyzing
  if(i %% 5000 == 0) print(paste('Analyzing SNP', i)) 
  # fit model
  mod <- lm(y ~ X.clean[,i])
  # get coefficient information
  coefinfo <- tidy(mod)
  # record estimate, SE, test stat, and p-value
  betas[i] <- coefinfo$estimate[2]
  ses[i] <- coefinfo$std.error[2]
  tstats[i] <- coefinfo$statistic[2]
  pvals[i] <- coefinfo$p.value[2]
}
```

Let's add our results to our map data frame that contains information about each SNP:

```{r chr1-results}
# start with the map info for the chr 1 SNPs
chr1.results <- map.clean %>%
  filter(chromosome == 1)

# then add betas, SEs, etc.
chr1.results <- chr1.results %>%
  mutate(Estimate = betas,
         Std.Error = ses,
         Test.Statistic = tstats,
         P.Value = pvals)

# look at results
head(chr1.results)
```


Now we're ready to plot our results! We'd like to get a visual of which SNPs have small p-values (suggesting a possible association between the SNP and the trait). To start, create a scatterplot of the p-value of each SNP versus its position along the chromosome.

```{r plot-pvals}
chr1.results %>%
  ggplot(aes(x = position, y = P.Value)) + 
  geom_point() + 
  labs(x = 'position (bp)', y = 'p-value') + 
  scale_x_continuous(labels = scales::comma)
```

What do you think? How well can you tell from this plot which SNPs have small p-values?

> Although this seems like a reasonable place to start in terms of plotting results, the result is a mess! It's really hard to see which SNPs have the smallest p-values.


One way to improve this visualization is to apply a log transformation to the p-values. When we have lots of numbers squished into a small range (0 to 1, in this case), a log transformation can be a nice way to spread these out. Try plotting the log (base 10) of the p-values for each SNP instead.

```{r plot-log-pvals}
chr1.results %>%
  mutate(logp = log10(P.Value)) %>%
  ggplot(aes(x = position, y = logp)) + 
  geom_point() + 
  labs(x = 'position (bp)', y = expression(paste('log'[10],'(p-value)'))) + 
  scale_x_continuous(labels = scales::comma)
```

What do you notice now? Are the SNPs with small p-values the ones with small (more negative) values or large (closer to 0) values on the log base 10 scale?

> The log transformation spread out the values so we can start to pick up on which p-values are smaller/larger than the others, now. 
> Recall that the log of 1 is `r log10(1)` and the log of anything between 0 and 1 will be negative. 
> For example: log(0.1) = `r log10(0.1)`, log(0.01) = `r log10(0.01)`, and log(0.001) = `r log(0.001)`.
> So, the SNPs with the smallest p-values in this plot are the ones with smaller (more negative) values.


A traditional Manhattan plot uses a negative log transformation instead. Try plotting the $-log_{10}$ p-values now:

```{r plot-minus-log-pvals}
chr1.results %>%
  mutate(minuslogp = -log10(P.Value)) %>%
  ggplot(aes(x = position, y = minuslogp)) + 
  geom_point() + 
  labs(x = 'position (bp)', y = expression(paste('-log'[10],'(p-value)'))) + 
  scale_x_continuous(labels = scales::comma)
```

What similarities do you notice between this plot and the Manhattan plots we've seen before? What differences do you notice? Discuss with your table.

> This looks a lot like the Manhattan plots we saw in our first Journal Club article and the plot we've seen a couple of times as the background photo of a slide in the lecture slides.
> A few differences that I notice: 
> 
> - we're only looking at one chromosome 
> - there is a gap in the middle of the plot (this is most likely where the [centromere](https://en.wikipedia.org/wiki/Centromere#Positions) of chromosome 1 is located; centromeres tend to be difficult to genotype)
> - there is no indication of which SNPs are significant (either via a horizontal dashed line or different colored points)  


### Analyze all chromosomes

As time allows, try repeating the analysis above, but now looking at the SNPs on other chromosomes as well. *Hint: the main thing you'll need to change is which SNPs you're looping over in your for loop.* 

```{r run-gwas-allchr, cache = TRUE}
# set up empty vectors for storing results
betas <- c()
ses <- c()
tstats <- c()
pvals <- c()

# loop through chromosome 1 SNPs
for(i in 1:ncol(X.clean)){
  # print out occasional updates telling us what SNP we're analyzing
  if(i %% 10000 == 0) print(paste('Analyzing SNP', i)) 
  # fit model
  mod <- lm(y ~ X.clean[,i])
  # get coefficient information
  coefinfo <- tidy(mod)
  # record estimate, SE, test stat, and p-value
  betas[i] <- coefinfo$estimate[2]
  ses[i] <- coefinfo$std.error[2]
  tstats[i] <- coefinfo$statistic[2]
  pvals[i] <- coefinfo$p.value[2]
}
```

```{r all-results}
# start with the map info for the chr 1 SNPs
all.results <- map.clean

# then add betas, SEs, etc.
all.results <- all.results %>%
  mutate(Estimate = betas,
         Std.Error = ses,
         Test.Statistic = tstats,
         P.Value = pvals)

# look at results
head(all.results)
```


```{r manh-attempt1, cache = T}
all.results %>%
  mutate(minuslogp = -log10(P.Value),
         chr = as.factor(chromosome)) %>%
  ggplot(aes(x = position, y = minuslogp, color = chr)) + 
  geom_point() + 
  labs(x = 'position (bp)', y = expression(paste('-log'[10],'(p-value)'))) + 
  scale_x_continuous(labels = scales::comma)
```

> Notice that the results from different chromosomes are getting plotted on top of one another! 
> This is because of the way we keep track of SNP locations: the position (bp) is relative to the chromosome, so the numbers start back over at zero with each new chromosome. 
> We can use the `group` aesthetic in ggplot to fix this:


```{r manh-attempt2, cache = T}
all.results %>%
  mutate(minuslogp = -log10(P.Value),
         chr = as.factor(chromosome)) %>%
  ggplot(aes(x = chr, y = minuslogp, group = interaction(chr, position), color = chr)) + 
  geom_point(position = position_dodge(0.8)) + 
  labs(x = 'chromosome', y = expression(paste('-log'[10],'(p-value)')))
```


```{r manh-change-colors, cache = T}
# try a different color palette
library(NatParksPalettes)
all.results %>%
  mutate(minuslogp = -log10(P.Value),
         chr = as.factor(chromosome)) %>%
  ggplot(aes(x = chr, y = minuslogp, group = interaction(chr, position), color = chr)) + 
  geom_point(position = position_dodge(0.8)) + 
  labs(x = 'chromosome', y = expression(paste('-log'[10],'(p-value)'))) + 
  scale_color_manual(values=natparks.pals("Olympic", 25)) + 
  theme(legend.position="none")
```

```{r manh-change-colors-again, cache = T}
# color palette to match the manh plot in the slides
## inspired by https://github.com/UW-GAC/analysis_pipeline
library(RColorBrewer)
chr <- levels(as.factor(all.results$chromosome))
cmap <- setNames(rep_len(brewer.pal(8, "Dark2"), length(chr)), chr)

# make plot
all.results %>%
  mutate(minuslogp = -log10(P.Value),
         chr = as.factor(chromosome)) %>%
  ggplot(aes(x = chr, y = minuslogp, group = interaction(chr, position), color = chr)) + 
  geom_point(position = position_dodge(0.8)) + 
  labs(x = 'chromosome', y = expression(paste('-log'[10],'(p-value)'))) + 
  scale_color_manual(values=cmap, breaks=names(cmap)) +
  theme(legend.position="none")
```



## Speed up the computation

The approach we've taken in this lab to implement marginal regression works, but it's not particularly efficient. Can you think of any ways that we could speed this up? Brainstorm some ideas with your group.

> Here are a few ideas:
> 
>- calculate marginal regression coefficient estimates and p-values "by hand" instead of using the `lm` function
>- use the `Rcpp` package to speed up the for loop
>- use the `parallel` package to split up the model fitting across different cores of your computer
>- use a tool specifically designed for this problem (like `PLINK`)
>- use a computer cluster or cloud computing (instead of trying to run the analysis on your laptop)

Note: this could make an interesting project topic!

